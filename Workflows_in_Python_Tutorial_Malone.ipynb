{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"blue\"> Workflows in Python</font>\n",
    "This is to follow the example code from [Katie Malone's blog post](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/) at Civis Analytics. This gives an example of a workflow model for Python. She describes as \n",
    "\n",
    "**\"a workflow that focuses on getting a quick-and-dirty model up and running as quickly as possible, and then going back to iterate on the weak points until the model seems to be converging on an answer.\"**\n",
    "\n",
    "- Dataset: “Pump it Up: Mining the Water Table” challenge on drivendata.org, which has examples of wells in Africa, their characteristics and whether they are **functional, non-functional, or functional but in need of repair.** \n",
    "\n",
    "-  Goal: build a model that will take the characteristics of a well and predict correctly which category that well falls into.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color = \"blue\"> [Part 1: Getting Data Ready to Build Models](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/) </font>\n",
    "\n",
    "# Getting started\n",
    "- read in data\n",
    "- transform features and labels to make the data amenable to machine learning\n",
    "- pick a modeling strategy (classification)\n",
    "- make a train/test split (this was done implicitly when I called cross_val_score)\n",
    "- evaluate several models for identifying wells that are failed or in danger of failing\n",
    "\n",
    "# 1. Labels\n",
    "## A quick print statement on the labels shows that the labels are strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  status_group\n",
      "id                            \n",
      "69572               functional\n",
      "8776                functional\n",
      "34310               functional\n",
      "67743           non functional\n",
      "19728               functional\n",
      "9944                functional\n",
      "19816           non functional\n",
      "54551           non functional\n",
      "53934           non functional\n",
      "46144               functional\n",
      "49056               functional\n",
      "50409               functional\n",
      "36957               functional\n",
      "50495               functional\n",
      "53752               functional\n",
      "61848               functional\n",
      "48451           non functional\n",
      "58155           non functional\n",
      "34169  functional needs repair\n",
      "18274               functional\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "features_df = pd.DataFrame.from_csv(\"data/training_set_values.csv\")\n",
    "labels_df   = pd.DataFrame.from_csv(\"data/training_set_labels.csv\") \n",
    "print(labels_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping labels to integers\n",
    "\"When I want a specific mapping between strings and integers, like here, doing it manually is usually the way I go.\"\n",
    "- there’s also the sklearn LabelEncoder.\n",
    "- pandas applymap()\n",
    "    - apply() vs. applymap(): applymap() operates on a whole dataframe while apply() operates on a series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas applymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       status_group\n",
      "id                 \n",
      "69572             2\n",
      "8776              2\n",
      "34310             2\n",
      "67743             0\n",
      "19728             2\n"
     ]
    }
   ],
   "source": [
    "def label_map(y):\n",
    "    if y==\"functional\":\n",
    "        return 2\n",
    "    elif y==\"functional needs repair\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "labels_df = labels_df.applymap(label_map)\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       amount_tsh date_recorded        funder  gps_height     installer  \\\n",
      "id                                                                        \n",
      "69572        6000    2011-03-14         Roman        1390         Roman   \n",
      "8776            0    2013-03-06       Grumeti        1399       GRUMETI   \n",
      "34310          25    2013-02-25  Lottery Club         686  World vision   \n",
      "67743           0    2013-01-28        Unicef         263        UNICEF   \n",
      "19728           0    2011-07-13   Action In A           0       Artisan   \n",
      "\n",
      "       longitude   latitude              wpt_name  num_private  \\\n",
      "id                                                               \n",
      "69572  34.938093  -9.856322                  none            0   \n",
      "8776   34.698766  -2.147466              Zahanati            0   \n",
      "34310  37.460664  -3.821329           Kwa Mahundi            0   \n",
      "67743  38.486161 -11.155298  Zahanati Ya Nanyumbu            0   \n",
      "19728  31.130847  -1.825359               Shuleni            0   \n",
      "\n",
      "                         basin          ...          payment_type  \\\n",
      "id                                      ...                         \n",
      "69572               Lake Nyasa          ...              annually   \n",
      "8776             Lake Victoria          ...             never pay   \n",
      "34310                  Pangani          ...            per bucket   \n",
      "67743  Ruvuma / Southern Coast          ...             never pay   \n",
      "19728            Lake Victoria          ...             never pay   \n",
      "\n",
      "      water_quality  quality_group      quantity quantity_group  \\\n",
      "id                                                                \n",
      "69572          soft           good        enough         enough   \n",
      "8776           soft           good  insufficient   insufficient   \n",
      "34310          soft           good        enough         enough   \n",
      "67743          soft           good           dry            dry   \n",
      "19728          soft           good      seasonal       seasonal   \n",
      "\n",
      "                     source           source_type source_class  \\\n",
      "id                                                               \n",
      "69572                spring                spring  groundwater   \n",
      "8776   rainwater harvesting  rainwater harvesting      surface   \n",
      "34310                   dam                   dam      surface   \n",
      "67743           machine dbh              borehole  groundwater   \n",
      "19728  rainwater harvesting  rainwater harvesting      surface   \n",
      "\n",
      "                   waterpoint_type waterpoint_type_group  \n",
      "id                                                        \n",
      "69572           communal standpipe    communal standpipe  \n",
      "8776            communal standpipe    communal standpipe  \n",
      "34310  communal standpipe multiple    communal standpipe  \n",
      "67743  communal standpipe multiple    communal standpipe  \n",
      "19728           communal standpipe    communal standpipe  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many of the features are categorical and they need to be transformed to numerical values.\n",
    "- transform categorical features: OneHotEncoder in sklearn or get_dummies() in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_feature( df, column_name ):\n",
    "    \n",
    "    \"\"\" take features_df and the name of a column in that dataframe, \n",
    "        and return the same dataframe but \n",
    "        with the indicated feature encoded with integers rather than strings\"\"\"\n",
    "    \n",
    "    unique_values = set( df[column_name].tolist() )\n",
    "    transformer_dict = {}\n",
    "    for ii, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = ii\n",
    "\n",
    "    def label_map(y):\n",
    "        return transformer_dict[y]\n",
    "    df[column_name] = df[column_name].apply( label_map )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       amount_tsh date_recorded  funder  gps_height  installer  longitude  \\\n",
      "id                                                                          \n",
      "69572        6000    2011-03-14    1539        1390       1749  34.938093   \n",
      "8776            0    2013-03-06     774        1399        136  34.698766   \n",
      "34310          25    2013-02-25     906         686       1400  37.460664   \n",
      "67743           0    2013-01-28     590         263        556  38.486161   \n",
      "19728           0    2011-07-13    1341           0        537  31.130847   \n",
      "\n",
      "        latitude  wpt_name  num_private  basin          ...            \\\n",
      "id                                                      ...             \n",
      "69572  -9.856322     15203            0      5          ...             \n",
      "8776   -2.147466      5611            0      7          ...             \n",
      "34310  -3.821329      6138            0      6          ...             \n",
      "67743 -11.155298      1252            0      1          ...             \n",
      "19728  -1.825359     29682            0      7          ...             \n",
      "\n",
      "       payment_type  water_quality  quality_group  quantity  quantity_group  \\\n",
      "id                                                                            \n",
      "69572             4              0              0         2               2   \n",
      "8776              5              0              0         1               1   \n",
      "34310             1              0              0         2               2   \n",
      "67743             5              0              0         0               0   \n",
      "19728             5              0              0         3               3   \n",
      "\n",
      "       source  source_type  source_class  waterpoint_type  \\\n",
      "id                                                          \n",
      "69572       1            1             1                1   \n",
      "8776        6            4             2                1   \n",
      "34310       7            5             2                4   \n",
      "67743       2            6             1                4   \n",
      "19728       6            4             2                1   \n",
      "\n",
      "       waterpoint_type_group  \n",
      "id                            \n",
      "69572                      1  \n",
      "8776                       1  \n",
      "34310                      1  \n",
      "67743                      1  \n",
      "19728                      1  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "['amount_tsh' 'funder' 'gps_height' 'installer' 'longitude' 'latitude'\n",
      " 'wpt_name' 'num_private' 'basin' 'subvillage' 'region' 'region_code'\n",
      " 'district_code' 'lga' 'ward' 'population' 'public_meeting' 'recorded_by'\n",
      " 'scheme_management' 'scheme_name' 'permit' 'construction_year'\n",
      " 'extraction_type' 'extraction_type_group' 'extraction_type_class'\n",
      " 'management' 'management_group' 'payment' 'payment_type' 'water_quality'\n",
      " 'quality_group' 'quantity' 'quantity_group' 'source' 'source_type'\n",
      " 'source_class' 'waterpoint_type' 'waterpoint_type_group']\n"
     ]
    }
   ],
   "source": [
    "### list of column names indicating which columns to transform; \n",
    "### this is just a start!  Use some of the print( labels_df.head() )\n",
    "### output upstream to help you decide which columns get the\n",
    "### transformation\n",
    "\n",
    "names_of_columns_to_transform = [\"funder\", \"installer\", \"wpt_name\", \"basin\", \"subvillage\",\n",
    "                    \"region\", \"lga\", \"ward\", \"public_meeting\", \"recorded_by\",\n",
    "                    \"scheme_management\", \"scheme_name\", \"permit\",\n",
    "                    \"extraction_type\", \"extraction_type_group\",\n",
    "                    \"extraction_type_class\",\n",
    "                    \"management\", \"management_group\",\n",
    "                    \"payment\", \"payment_type\",\n",
    "                    \"water_quality\", \"quality_group\", \"quantity\", \"quantity_group\",\n",
    "                    \"source\", \"source_type\", \"source_class\",\n",
    "                    \"waterpoint_type\", \"waterpoint_type_group\"]\n",
    "\n",
    "for column in names_of_columns_to_transform:\n",
    "    features_df = transform_feature( features_df, column )\n",
    "    \n",
    "print( features_df.head() )\n",
    "    \n",
    "### remove the \"date_recorded\" column--we're not going to make use\n",
    "### of time-series data today\n",
    "features_df.drop(\"date_recorded\", axis=1, inplace=True)\n",
    "\n",
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep for sklearn: convert it to numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df[\"status_group\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and test \n",
    "- The cheapest and easiest way to train on one portion of my dataset and test on another, and to get a measure of model quality at the same time, is to use **sklearn.cross_validation.cross_val_score()**\n",
    "    - Splits my data into three equal portions, trains on two of them, and tests on the third\n",
    "    - This process repeats three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68363636  0.6830303   0.6859596 ]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification or Regression\n",
    "- I have the choice of **modeling with a classifier** and potentially getting slightly worse performance, \n",
    "- or building **a regression but needing to add a post-processing step that turns my continuous (i.e. float) predictions into integer category labels.** \n",
    "- I’ve decided to go with the classification approach for this example, but this is a decision made for convenience that I could revisit when improving my model down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare algorithms\n",
    "- I started with a simple logistic regression above (despite the name, this is a classification algorithm) \n",
    "- I’ll compare to a couple of other classifiers, a decision tree classifier and a random forest classifier, to see which one seems to do the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.73959596  0.73580808  0.73020202]\n",
      "[ 0.78868687  0.78929293  0.78893939]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# <font color = \"blue\"> [Part 2: Curating Features and Thinking Scientifically about Algorithms](https://civisanalytics.com/blog/data-science/2015/12/23/workflows-in-python-curating-features-and-thinking-scientifically-about-algorithms/) </font>\n",
    "\n",
    "# 1. Revisiting numerical encoding of categorical features\n",
    "\n",
    "- A problem with representing categorical variables as integers is that **integers are ordered**, while categories are not. \n",
    "- The standard way to deal with this is to use **dummy variables**; **one-hot encoding** is a very common way of dummying. \n",
    "\n",
    "## One-hot encoding\n",
    "- The categories are expanded over several boolean columns, only one of which is true (hot). \n",
    "- the scikit-learn `OneHotEncoder` object or pandas `get_dummies()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "def hot_encoder(df, column_name):\n",
    "    \n",
    "    \"\"\"\n",
    "        a one-hot-encoder function \n",
    "        that takes the data frame and the title of a column, and \n",
    "        returns the same data frame but one-hot encoding performed on the indicated feature\n",
    "    \"\"\"\n",
    "    \n",
    "    column = df[column_name].tolist()\n",
    "    column = np.reshape( column, (len(column), 1) )  ### needs to be an N x 1 numpy array\n",
    "    enc = sklearn.preprocessing.OneHotEncoder()\n",
    "    enc.fit( column )\n",
    "    new_column = enc.transform( column ).toarray()\n",
    "    column_titles = []\n",
    "    \n",
    "    ### making titles for the new columns, and appending them to dataframe\n",
    "    for ii in range( len(new_column[0]) ):\n",
    "        this_column_name = column_name+\"_\"+str(ii)\n",
    "        df[this_column_name] = new_column[:,ii]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding makes the dataset bigger–sometimes a lot bigger. \n",
    "You can imagine that this can sometimes get really, really big (imagine a column encoding all the counties in the United States, for example).\n",
    "- There are some columns in this example that will really blow up the dataset, so I’ll remove them before proceeding with the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amount_tsh' 'funder' 'gps_height' 'installer' 'longitude' 'latitude'\n",
      " 'wpt_name' 'num_private' 'basin' 'subvillage' 'region' 'region_code'\n",
      " 'district_code' 'lga' 'ward' 'population' 'public_meeting' 'recorded_by'\n",
      " 'scheme_management' 'scheme_name' 'permit' 'construction_year'\n",
      " 'extraction_type' 'extraction_type_group' 'extraction_type_class'\n",
      " 'management' 'management_group' 'payment' 'payment_type' 'water_quality'\n",
      " 'quality_group' 'quantity' 'quantity_group' 'source' 'source_type'\n",
      " 'source_class' 'waterpoint_type' 'waterpoint_type_group']\n"
     ]
    }
   ],
   "source": [
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df.drop( \"funder\", axis=1, inplace=True )\n",
    "features_df.drop( \"installer\", axis=1, inplace=True )\n",
    "features_df.drop( \"wpt_name\", axis=1, inplace=True )\n",
    "features_df.drop( \"subvillage\", axis=1, inplace=True )\n",
    "features_df.drop( \"ward\", axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_of_columns_to_transform.remove(\"funder\")\n",
    "names_of_columns_to_transform.remove(\"installer\")\n",
    "names_of_columns_to_transform.remove(\"wpt_name\")\n",
    "names_of_columns_to_transform.remove(\"subvillage\")\n",
    "names_of_columns_to_transform.remove(\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-02c9e8557f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcont_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_of_columns_to_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhot_encoder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for feature in names_of_columns_to_transform:\n",
    "    features_df = hot_encoder( features_df, feature )\n",
    "\n",
    "print( features_df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 3000 features (origianlly we had about 40). \n",
    "\n",
    "# 2. Feature selection\n",
    "Having so many features invites problems with overfitting, slow and memory-intensive training.\n",
    "- This is a perfect use case for feature selection, which is supported in scikit-learn by e.g. `SelectKBest()`, which will do **univariate feature selection** to get the k features (where k is a number which I have to tell the algorithm). \n",
    "- Making a guess, I can ask for the top 100 features, which doesn’t make my performance much worse and speeds things up a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hongsup/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:111: UserWarning: Features [ 12 191] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "X = features_df.as_matrix()\n",
    "selected_X = select.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Back to Machine Learning\n",
    "In the last post, a **random forest classifier did the best** of all the models I tried, beating a logistic regression (by a lot) and a decision tree classifier (by a slimmer margin). \n",
    "\n",
    "Here are a few reasons why:\n",
    "\n",
    "## Logistic regression\n",
    "- A logistic regression is **an example of a linear model**, which (unless you make special adaptations, which I’ll detail in a moment) assumes that **the relationship between each of my features and the output class is a linear one**. For example, if one of the features is the depth of a well, a linear model will assume that (all other things being equal) the difference in functionality between a 20-foot-deep well and a 40-foot-deep one will be the same as the difference between 40 feet and 60 feet. This isn’t always a valid assumption. \n",
    "    - **One way to address it is to add extra features** like depth squared and the logarithm of depth, which helps a linear model capture nonlinearities, but might not still allow me to get all the nuances of nonlinear relationships.\n",
    "\n",
    "- A logistic regression also **doesn’t capture interactions between features**, for example that deep wells might be largely functional and wells drilled in rock are largely functional but deep wells in rocky places are largely non-functional. \n",
    "    - Again, I can explicitly add interaction terms to the logistic regression, but this **gets unwieldy fast when I have many features.**\n",
    "\n",
    "\n",
    "## Decision Tree\n",
    "- A decision tree **can capture interactions and nonlinearities much more naturally than logistic regression**, because of the binary tree structure of the decision tree algorithm itself. \n",
    "    - The downside of decision trees is that **they can be harder to interpret or assign uncertainties to their predictions.**\n",
    "\n",
    "## Random Forest\n",
    "- A random forest is a collection of decision trees, each of which is trained on **a subset of the rows/columns** of the training data. The randomness in the training set means that the individual trees in a random forest are high-variance, but low-bias, and the final prediction is made by **having each tree classify a given event and then using their predictions as “votes,” with the majority opinion being assigned as the label**. \n",
    "- I have the nonlinearities and interactions being **captured by the individual trees**, but ensembling many trees into a random forest tends to **cancel out the biases/shortcomings of any one tree** and I get a stronger predictor overall.\n",
    "- In [empirical studies](https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf) of many algorithms being applied to many **supervised learning problems**, random forests often come out on top overall. So **when in doubt, or if I only have the time/resources to try one model**, a random forest is likely to get at or near the peak performance of all the algorithms on the market.\n",
    "- If it was tricky to interpret or compute errors for a decision tree, a random forest is only going to be worse because there’s now 50-100 decision trees to worry about.\n",
    "\n",
    "## Random forests have lots of parameters to optimize. \n",
    "- How many trees should there be? \n",
    "- How does each tree get trained? \n",
    "- How many features get used in training each tree? \n",
    "\n",
    "There usually aren’t formulaic answers to these questions, and part of the craft of machine learning is **tuning these parameters to get the best performance** that I can out of my model. \n",
    "- But with so many parameters, which sometimes interact with each other in complex ways, parameter tuning can be a huge hassle. \n",
    "- In the next post, I’ll talk about an extremely powerful pair of tools in scikit-learn, the Pipeline and GridSearchCV, that allow crazy powerful parameter tuning in just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Part 3: Using Pipeline and GridSearchCV for More Compact and Comprehensive Code](https://civisanalytics.com/blog/data-science/2016/01/06/workflows-python-using-pipeline-gridsearchcv-for-compact-code/)\n",
    "\n",
    "- Now we're left with **a lot of free parameters of the algorithms to tune**, and messing around with the workflow often leads to **spaghetti code** that becomes less and less understandable/easy to experiment with as we go.\n",
    "- Enter the scikit-learn Pipeline and GridSearchCV objects: two tools that effectively allow us to pour gasoline on  data science fire, tightening up the code and doing parameter scans in just a few lines of code.\n",
    "\n",
    "# 1. Pipeline\n",
    "- There are a number of tools that I’ve chained together to get where I am now, like SelectKBest and RandomForestClassifier. After selecting the 100 best features, **the natural next step is to run my random forest again to see if it does a little better with fewer features.** In this case, I have SelectKBest doing selection, with the output of that process going straight into a classifier. \n",
    "- **Pipeline packages the transformation step of SelectKBest with the estimation step of RandomForestClassifier into a coherent workflow.**\n",
    "\n",
    "\n",
    "## Benefit\n",
    "- It makes code more **readable** (or, if you like, it makes the intent of the code clearer).\n",
    "- I don’t have to worry about keeping track data during intermediate steps, for example between transforming and estimating.\n",
    "- It makes it trivial to move ordering of the pipeline pieces, or to swap pieces in and out.\n",
    "- **It allows you to do `GridSearchCV` on your workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.77      0.77      7458\n",
      "          1       0.42      0.36      0.39      1425\n",
      "          2       0.80      0.81      0.81     10719\n",
      "\n",
      "avg / total       0.76      0.76      0.76     19602\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hongsup/anaconda/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:111: UserWarning: Features [  12  191  206  211  232  238  273  278  287  291  302  303  307  313  322\n",
      "  324  325  344  353  359  371  378  383  423  429  432  433  437  440  444\n",
      "  450  453  479  481  496  509  523  529  533  540  542  546  549  561  566\n",
      "  597  609  620  648  649  656  684  700  727  735  748  751  761  782  797\n",
      "  810  812  816  826  829  836  845  847  853  855  856  867  889  894  903\n",
      "  905  912  944  946  965  975  977 1005 1024 1026 1034 1036 1048 1051 1052\n",
      " 1053 1070 1077 1096 1106 1118 1120 1139 1145 1146 1157 1158 1161 1172 1174\n",
      " 1180 1188 1191 1197 1200 1203 1205 1242 1244 1247 1256 1262 1277 1283 1286\n",
      " 1287 1290 1293 1294 1298 1307 1312 1315 1326 1335 1362 1366 1374 1398 1399\n",
      " 1402 1405 1418 1423 1425 1426 1429 1432 1441 1456 1482 1494 1500 1511 1522\n",
      " 1530 1537 1545 1560 1561 1563 1566 1586 1606 1613 1620 1628 1629 1637 1638\n",
      " 1640 1645 1653 1676 1688 1707 1715 1717 1719 1720 1722 1725 1726 1735 1739\n",
      " 1740 1754 1758 1762 1799 1818 1825 1835 1838 1845 1852 1866 1873 1874 1880\n",
      " 1883 1887 1899 1910 1915 1922 1931 1945 1947 1960 1968 1969 1992 1994 2009\n",
      " 2010 2023 2027 2039 2042 2049 2066 2074 2081 2109 2122 2124 2128 2130 2139\n",
      " 2162 2165 2170 2196 2197 2212 2217 2220 2239 2262 2291 2305 2307 2322 2327\n",
      " 2336 2347 2354 2373 2375 2408 2417 2434 2436 2456 2466 2476 2478 2479 2485\n",
      " 2490 2501 2504 2506 2525 2526 2532 2539 2540 2548 2559 2579 2590 2596 2597\n",
      " 2608 2620 2629 2633 2634 2640 2659 2671 2675 2679 2686 2688 2693 2699 2702\n",
      " 2703 2723 2729 2738 2745 2753 2755 2763 2767 2772 2775 2784 2786 2795 2825\n",
      " 2826 2827 2841 2880 2900] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.pipeline\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=100)\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "steps = [('feature_selection', select), ('random_forest', clf)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "### fit your pipeline on X_train and y_train\n",
    "pipeline.fit( X_train, y_train )\n",
    "\n",
    "### call pipeline.predict() on your X_test data to make a set of test predictions\n",
    "y_prediction = pipeline.predict( X_test )\n",
    "\n",
    "### test your predictions using sklearn.classification_report()\n",
    "### classification_report gives more info than cross_val_score\n",
    "### But we need to split train/test separately (with cross_val_score, you don't have to)\n",
    "report = sklearn.metrics.classification_report( y_test, y_prediction )\n",
    "\n",
    "### and print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GridSearchCV\n",
    "\n",
    "When I decided to select the 100 best features, setting that number to 100 was kind of a hand-wavey decision. Similarly, the RandomForestClassifier that I’m using right now has all its parameters set to their default values, which might not be optimal.\n",
    "\n",
    "So, a straightforward thing to do now is **to try different values of k** (the number of features being used in the model) and **any RandomForestClassifier parameters I want to tune** (for the sake of concreteness, I’ll play with n_estimators and min_samples_split).\n",
    "\n",
    "- Trying lots of values for each of these free parameters is tedious\n",
    "- There can sometimes be interactions between the choices I make in one step and the optimal value for a downstream step. \n",
    "- To avoid local optima, I should try all the combinations of parameters, and not just vary them independently. If I want to try 5 different values each for k, n_estimators and min_samples_split, that means 5 x 5 x 5 = 125 different combinations to try. Not something I want to do by hand.\n",
    "\n",
    "`GridSearchCV` allows me to construct a grid of all the combinations of parameters, tries each combination, and then reports back the best combination/model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.grid_search\n",
    "\n",
    "parameters = dict(feature_selection__k=[100, 200], \n",
    "              random_forest__n_estimators=[50, 100, 200],\n",
    "              random_forest__min_samples_split=[2, 3, 4, 5, 10])\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "y_predictions = cv.predict(X_test)\n",
    "report = sklearn.metrics.classification_report( y_test, y_predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.77      0.80      7458\n",
      "          1       0.56      0.30      0.39      1425\n",
      "          2       0.80      0.89      0.84     10719\n",
      "\n",
      "avg / total       0.79      0.80      0.79     19602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV seems a little scary at first, because the parameter grid is easy to mess up. \n",
    "There’s **a particular convention** being followed in the way that **the parameters are named in the parameters dictionary.**\n",
    "- I need to have the name of the Pipeline step (e.g. feature_selection, not select; or random_forest, not clf), followed by **two underscores**, followed by the name of the parameter (in sklearn parlance) that I want to vary. \n",
    "\n",
    "To put this all together in a painfully simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "steps = [(\"my_classifier\", clf)]\n",
    "\n",
    "### “my_classifier” is the name of the random forest classifier in the steps list; \n",
    "### min_samples_split is the associated sklearn parameter that I want to vary\n",
    "parameters = dict{my_classifier__min_samples_split=[2, 3, 4, 5]}  \n",
    "pipe = Pipeline(steps)\n",
    "cv = GridSearchCV( pipe, param_grid = parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I’ve got the parameter grid set up properly, the power of GridSearchCV is that it multiplies out all the combinations of parameters and tries each one, making a 3-fold cross-validated model for each combination. Then I can ask for predictions from my GridSearchCV object and it will **automatically return to me the “best” set of predictions** (that is, the predictions from the best model that it tried), or I can explicitly ask for the best model/best parameters using methods associated with GridSearchCV. Of course, trying tons of models can be kind of time-consuming, but the outcome is a much better understanding of how my model performance depends on parameters.\n",
    "\n",
    "## GridSearchCV can be used as a single object.\n",
    "I should also mention that I can also use GridSearchCV on just a single object, rather than a full Pipeline. For example, I can optimize SelectKBest or the RandomForestClassifier on their own and that will work just fine. But since there can sometimes be interactions between various steps in the analysis, being able to optimize over the full Pipeline is really useful. It’s also trickier to do, which makes it a good example for teaching. \n",
    "- Last, GridSearchCV will **automatically cross validate all steps of the analysis**, such as the feature selection–it’s not just the final algorithm that should be cross-validated, but the upstream transforms as well!\n",
    "\n",
    "-----\n",
    "# Tutorial Summary\n",
    "This brings me to the end of this series, about **end-to-end data analysis in scikit-learn and pandas**. \n",
    "\n",
    "My goal in these posts is not to show a perfect analysis, or even one that demonstrates all the steps one might try, but instead to **focus on the process**. \n",
    "- If I can get something up and running quickly, even if it’s imperfect, I’m in a much better position to understand later on how much my refinements are indeed improving the analysis. \n",
    "- At the same time, there are definitely best practices and tools (like Pipeline and GridSearchCV) that will make my life much easier as my work expands. \n",
    "- Having a great set of tools in the python data science stack, and knowing when and how to deploy them, leaves me free to spend my time and energy on the most interesting, important and difficult-to-automate tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
