{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflows in Python: Getting data ready to build models\n",
    "\n",
    "This is to follow the example code from [Katie Malone's blog post](https://civisanalytics.com/blog/data-science/2015/12/17/workflows-in-python-getting-data-ready-to-build-models/) at Civis Analytics. This gives an example of a workflow model for Python. She describes as \n",
    "\n",
    "**\"a workflow that focuses on getting a quick-and-dirty model up and running as quickly as possible, and then going back to iterate on the weak points until the model seems to be converging on an answer.\"**\n",
    "\n",
    "- Dataset: “Pump it Up: Mining the Water Table” challenge on drivendata.org, which has examples of wells in Africa, their characteristics and whether they are **functional, non-functional, or functional but in need of repair.** \n",
    "\n",
    "-  Goal: build a model that will take the characteristics of a well and predict correctly which category that well falls into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "- read in data\n",
    "- transform features and labels to make the data amenable to machine learning\n",
    "- pick a modeling strategy (classification)\n",
    "- make a train/test split (this was done implicitly when I called cross_val_score)\n",
    "- evaluate several models for identifying wells that are failed or in danger of failing\n",
    "\n",
    "# 1. Labels\n",
    "## A quick print statement on the labels shows that the labels are strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  status_group\n",
      "id                            \n",
      "69572               functional\n",
      "8776                functional\n",
      "34310               functional\n",
      "67743           non functional\n",
      "19728               functional\n",
      "9944                functional\n",
      "19816           non functional\n",
      "54551           non functional\n",
      "53934           non functional\n",
      "46144               functional\n",
      "49056               functional\n",
      "50409               functional\n",
      "36957               functional\n",
      "50495               functional\n",
      "53752               functional\n",
      "61848               functional\n",
      "48451           non functional\n",
      "58155           non functional\n",
      "34169  functional needs repair\n",
      "18274               functional\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "features_df = pd.DataFrame.from_csv(\"data/training_set_values.csv\")\n",
    "labels_df   = pd.DataFrame.from_csv(\"data/training_set_labels.csv\") \n",
    "print(labels_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping labels to integers\n",
    "\"When I want a specific mapping between strings and integers, like here, doing it manually is usually the way I go.\"\n",
    "- there’s also the sklearn LabelEncoder.\n",
    "- pandas applymap()\n",
    "    - apply() vs. applymap(): applymap() operates on a whole dataframe while apply() operates on a series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas applymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       status_group\n",
      "id                 \n",
      "69572             2\n",
      "8776              2\n",
      "34310             2\n",
      "67743             0\n",
      "19728             2\n"
     ]
    }
   ],
   "source": [
    "def label_map(y):\n",
    "    if y==\"functional\":\n",
    "        return 2\n",
    "    elif y==\"functional needs repair\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "labels_df = labels_df.applymap(label_map)\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       amount_tsh date_recorded        funder  gps_height     installer  \\\n",
      "id                                                                        \n",
      "69572        6000    2011-03-14         Roman        1390         Roman   \n",
      "8776            0    2013-03-06       Grumeti        1399       GRUMETI   \n",
      "34310          25    2013-02-25  Lottery Club         686  World vision   \n",
      "67743           0    2013-01-28        Unicef         263        UNICEF   \n",
      "19728           0    2011-07-13   Action In A           0       Artisan   \n",
      "\n",
      "       longitude   latitude              wpt_name  num_private  \\\n",
      "id                                                               \n",
      "69572  34.938093  -9.856322                  none            0   \n",
      "8776   34.698766  -2.147466              Zahanati            0   \n",
      "34310  37.460664  -3.821329           Kwa Mahundi            0   \n",
      "67743  38.486161 -11.155298  Zahanati Ya Nanyumbu            0   \n",
      "19728  31.130847  -1.825359               Shuleni            0   \n",
      "\n",
      "                         basin          ...          payment_type  \\\n",
      "id                                      ...                         \n",
      "69572               Lake Nyasa          ...              annually   \n",
      "8776             Lake Victoria          ...             never pay   \n",
      "34310                  Pangani          ...            per bucket   \n",
      "67743  Ruvuma / Southern Coast          ...             never pay   \n",
      "19728            Lake Victoria          ...             never pay   \n",
      "\n",
      "      water_quality  quality_group      quantity quantity_group  \\\n",
      "id                                                                \n",
      "69572          soft           good        enough         enough   \n",
      "8776           soft           good  insufficient   insufficient   \n",
      "34310          soft           good        enough         enough   \n",
      "67743          soft           good           dry            dry   \n",
      "19728          soft           good      seasonal       seasonal   \n",
      "\n",
      "                     source           source_type source_class  \\\n",
      "id                                                               \n",
      "69572                spring                spring  groundwater   \n",
      "8776   rainwater harvesting  rainwater harvesting      surface   \n",
      "34310                   dam                   dam      surface   \n",
      "67743           machine dbh              borehole  groundwater   \n",
      "19728  rainwater harvesting  rainwater harvesting      surface   \n",
      "\n",
      "                   waterpoint_type waterpoint_type_group  \n",
      "id                                                        \n",
      "69572           communal standpipe    communal standpipe  \n",
      "8776            communal standpipe    communal standpipe  \n",
      "34310  communal standpipe multiple    communal standpipe  \n",
      "67743  communal standpipe multiple    communal standpipe  \n",
      "19728           communal standpipe    communal standpipe  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many of the features are categorical and they need to be transformed to numerical values.\n",
    "- transform categorical features: OneHotEncoder in sklearn or get_dummies() in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_feature( df, column_name ):\n",
    "    \n",
    "    \"\"\" take features_df and the name of a column in that dataframe, \n",
    "        and return the same dataframe but \n",
    "        with the indicated feature encoded with integers rather than strings\"\"\"\n",
    "    \n",
    "    unique_values = set( df[column_name].tolist() )\n",
    "    transformer_dict = {}\n",
    "    for ii, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = ii\n",
    "\n",
    "    def label_map(y):\n",
    "        return transformer_dict[y]\n",
    "    df[column_name] = df[column_name].apply( label_map )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       amount_tsh date_recorded  funder  gps_height  installer  longitude  \\\n",
      "id                                                                          \n",
      "69572        6000    2011-03-14    1539        1390       1749  34.938093   \n",
      "8776            0    2013-03-06     774        1399        136  34.698766   \n",
      "34310          25    2013-02-25     906         686       1400  37.460664   \n",
      "67743           0    2013-01-28     590         263        556  38.486161   \n",
      "19728           0    2011-07-13    1341           0        537  31.130847   \n",
      "\n",
      "        latitude  wpt_name  num_private  basin          ...            \\\n",
      "id                                                      ...             \n",
      "69572  -9.856322     15203            0      5          ...             \n",
      "8776   -2.147466      5611            0      7          ...             \n",
      "34310  -3.821329      6138            0      6          ...             \n",
      "67743 -11.155298      1252            0      1          ...             \n",
      "19728  -1.825359     29682            0      7          ...             \n",
      "\n",
      "       payment_type  water_quality  quality_group  quantity  quantity_group  \\\n",
      "id                                                                            \n",
      "69572             4              0              0         2               2   \n",
      "8776              5              0              0         1               1   \n",
      "34310             1              0              0         2               2   \n",
      "67743             5              0              0         0               0   \n",
      "19728             5              0              0         3               3   \n",
      "\n",
      "       source  source_type  source_class  waterpoint_type  \\\n",
      "id                                                          \n",
      "69572       1            1             1                1   \n",
      "8776        6            4             2                1   \n",
      "34310       7            5             2                4   \n",
      "67743       2            6             1                4   \n",
      "19728       6            4             2                1   \n",
      "\n",
      "       waterpoint_type_group  \n",
      "id                            \n",
      "69572                      1  \n",
      "8776                       1  \n",
      "34310                      1  \n",
      "67743                      1  \n",
      "19728                      1  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "['amount_tsh' 'funder' 'gps_height' 'installer' 'longitude' 'latitude'\n",
      " 'wpt_name' 'num_private' 'basin' 'subvillage' 'region' 'region_code'\n",
      " 'district_code' 'lga' 'ward' 'population' 'public_meeting' 'recorded_by'\n",
      " 'scheme_management' 'scheme_name' 'permit' 'construction_year'\n",
      " 'extraction_type' 'extraction_type_group' 'extraction_type_class'\n",
      " 'management' 'management_group' 'payment' 'payment_type' 'water_quality'\n",
      " 'quality_group' 'quantity' 'quantity_group' 'source' 'source_type'\n",
      " 'source_class' 'waterpoint_type' 'waterpoint_type_group']\n"
     ]
    }
   ],
   "source": [
    "### list of column names indicating which columns to transform; \n",
    "### this is just a start!  Use some of the print( labels_df.head() )\n",
    "### output upstream to help you decide which columns get the\n",
    "### transformation\n",
    "\n",
    "names_of_columns_to_transform = [\"funder\", \"installer\", \"wpt_name\", \"basin\", \"subvillage\",\n",
    "                    \"region\", \"lga\", \"ward\", \"public_meeting\", \"recorded_by\",\n",
    "                    \"scheme_management\", \"scheme_name\", \"permit\",\n",
    "                    \"extraction_type\", \"extraction_type_group\",\n",
    "                    \"extraction_type_class\",\n",
    "                    \"management\", \"management_group\",\n",
    "                    \"payment\", \"payment_type\",\n",
    "                    \"water_quality\", \"quality_group\", \"quantity\", \"quantity_group\",\n",
    "                    \"source\", \"source_type\", \"source_class\",\n",
    "                    \"waterpoint_type\", \"waterpoint_type_group\"]\n",
    "\n",
    "for column in names_of_columns_to_transform:\n",
    "    features_df = transform_feature( features_df, column )\n",
    "    \n",
    "print( features_df.head() )\n",
    "    \n",
    "### remove the \"date_recorded\" column--we're not going to make use\n",
    "### of time-series data today\n",
    "features_df.drop(\"date_recorded\", axis=1, inplace=True)\n",
    "\n",
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep for sklearn: convert it to numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df[\"status_group\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and test \n",
    "- The cheapest and easiest way to train on one portion of my dataset and test on another, and to get a measure of model quality at the same time, is to use **sklearn.cross_validation.cross_val_score()**\n",
    "    - Splits my data into three equal portions, trains on two of them, and tests on the third\n",
    "    - This process repeats three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68707071  0.68429293  0.6809596 ]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification or Regression\n",
    "- I have the choice of **modeling with a classifier** and potentially getting slightly worse performance, \n",
    "- or building **a regression but needing to add a post-processing step that turns my continuous (i.e. float) predictions into integer category labels.** \n",
    "- I’ve decided to go with the classification approach for this example, but this is a decision made for convenience that I could revisit when improving my model down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare algorithms\n",
    "- I started with a simple logistic regression above (despite the name, this is a classification algorithm) \n",
    "- I’ll compare to a couple of other classifiers, a decision tree classifier and a random forest classifier, to see which one seems to do the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.74242424  0.73717172  0.73393939]\n",
      "[ 0.78656566  0.78747475  0.78242424]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print( score )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
